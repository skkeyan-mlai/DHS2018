{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basecamp\n",
    "\n",
    "### Karthikeyan Sankaran, 17th June, 2018\n",
    "\n",
    "### End to End ML Pipeline [BigMart Sales]: Notebook 4 - Running Algorithms & Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from generic_transformers import *\n",
    "from utility_functions import (Find_Optimal_Cutoff,_get_feature_importances)\n",
    "\n",
    "from category_encoders import (BackwardDifferenceEncoder,BinaryEncoder,HashingEncoder,HelmertEncoder,\n",
    "                               OneHotEncoder,OrdinalEncoder,SumEncoder,PolynomialEncoder)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(act_y, pred_y):\n",
    "    return np.sqrt(mse(act_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Driver parameters\n",
    "\n",
    "#1. Scoring\n",
    "#scoring = 'neg_mean_squared_error'\n",
    "#scoring = 'neg_mean_absolute_error'\n",
    "#scoring = 'neg_median_absolute_error'\n",
    "scoring = 'r2'\n",
    "\n",
    "#2. Folds\n",
    "cv_indicator = 'kfold' # can be - 'shuffle_split','kfold','time', 'rkfold', 'loo', 'skfold', 's_shuffle_split'\n",
    "n_splits=5\n",
    "seed = 10\n",
    "\n",
    "#3. Tuning\n",
    "tuning_required = \"Yes\"\n",
    "search = 'grid_search'\n",
    "\n",
    "#4. Target\n",
    "target = 'Item_Outlet_Sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r train_feats\n",
    "%store -r test_feats\n",
    "%store -r target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_feats.copy()\n",
    "test_df = test_feats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 62) (5681, 62) (8523, 4)\n"
     ]
    }
   ],
   "source": [
    "print (train_df.shape, test_df.shape, target_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8523 entries, 0 to 8522\n",
      "Data columns (total 62 columns):\n",
      "Item_Fat_Content                                 8523 non-null object\n",
      "Item_Identifier                                  8523 non-null object\n",
      "Item_MRP                                         8523 non-null float64\n",
      "Item_Outlet_Sales                                8523 non-null float64\n",
      "Item_Type                                        8523 non-null object\n",
      "Item_Visibility                                  8523 non-null float64\n",
      "Item_Weight                                      7060 non-null float64\n",
      "Outlet_Establishment_Year                        8523 non-null int64\n",
      "Outlet_Identifier                                8523 non-null object\n",
      "Outlet_Location_Type                             8523 non-null object\n",
      "Outlet_Size                                      6113 non-null object\n",
      "Outlet_Type                                      8523 non-null object\n",
      "source                                           8523 non-null object\n",
      "Outlet_Size_Imputed                              8523 non-null object\n",
      "Outlet_Size_FillNA                               8523 non-null object\n",
      "Outlet_Size_NaN                                  8523 non-null object\n",
      "Item_Weight_Imputed                              8523 non-null float64\n",
      "Item_Weight_FillNA                               8523 non-null float64\n",
      "Item_Weight_NaN                                  8523 non-null object\n",
      "Item_Visibility_Imputed                          8523 non-null float64\n",
      "Item_Visibility_FillNA                           8523 non-null float64\n",
      "Item_Visibility_NaN                              8523 non-null object\n",
      "Item_Fat_Content_modified                        8523 non-null object\n",
      "Item_Type_Combined                               8523 non-null object\n",
      "Outlet_Years                                     8523 non-null int64\n",
      "PriceLevels                                      8523 non-null object\n",
      "WeightLevels                                     7060 non-null object\n",
      "VisibilityLevels                                 8523 non-null object\n",
      "Item_MRP_clipped                                 8523 non-null float64\n",
      "Outlet_Type:T.Supermarket Type1::Outlet_Years    8523 non-null float64\n",
      "Outlet_Type:T.Supermarket Type2::Outlet_Years    8523 non-null float64\n",
      "Outlet_Type:T.Supermarket Type3::Outlet_Years    8523 non-null float64\n",
      "Outlet_Years:Item_MRP_clipped                    8523 non-null float64\n",
      "Item_Identifier_avg_Item_MRP                     8523 non-null float64\n",
      "Item_Identifier_avg_Item_Outlet_Sales            8523 non-null float64\n",
      "Outlet_Identifier_avg_Item_MRP                   8523 non-null float64\n",
      "Outlet_Identifier_avg_Item_Outlet_Sales          8523 non-null float64\n",
      "Item_Identifier_mean_enc                         8523 non-null float64\n",
      "Outlet_Identifier_mean_enc                       8523 non-null float64\n",
      "Item_Identifier_mean_enc_fold                    8523 non-null float64\n",
      "Outlet_Identifier_mean_enc_fold                  8523 non-null float64\n",
      "ClusterName                                      8523 non-null object\n",
      "Outlet_Size_Imputed_lb_enc                       8523 non-null int32\n",
      "Outlet_Size_FillNA_lb_enc                        8523 non-null int32\n",
      "Outlet_Size_NaN_lb_enc                           8523 non-null int32\n",
      "Item_Weight_NaN_lb_enc                           8523 non-null int32\n",
      "Item_Visibility_NaN_lb_enc                       8523 non-null int32\n",
      "Item_Fat_Content_modified_lb_enc                 8523 non-null int32\n",
      "Item_Type_Combined_lb_enc                        8523 non-null int32\n",
      "PriceLevels_lb_enc                               8523 non-null int32\n",
      "WeightLevels_lb_enc                              8523 non-null int32\n",
      "VisibilityLevels_lb_enc                          8523 non-null int32\n",
      "ClusterName_lb_enc                               8523 non-null int32\n",
      "Item_Identifier_freq                             8523 non-null int64\n",
      "Outlet_Identifier_freq                           8523 non-null int64\n",
      "Outlet_Type_freq                                 8523 non-null int64\n",
      "Item_MRP_clipped_tf                              8523 non-null float64\n",
      "Item_Visibility_Imputed_tf                       8523 non-null float64\n",
      "Item_Weight_Imputed_tf                           8523 non-null float64\n",
      "pca_1                                            8523 non-null float64\n",
      "pca_2                                            8523 non-null float64\n",
      "pca_3                                            8523 non-null float64\n",
      "dtypes: float64(27), int32(11), int64(5), object(19)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pipeline - Level 0 - For evaluating multiple feature sets & algorithms **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_regressors = [\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor(),\n",
    "    XGBRegressor(),\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "feature_set_0 = []  # Just to ensure that feature set 1 starts with index 1 - for convenience\n",
    "feature_set_1 = ['Item_Identifier_mean_enc_fold','Outlet_Identifier_mean_enc_fold','Item_MRP_clipped_tf','PriceLevels_lb_enc']\n",
    "feature_set_2 = ['Item_Identifier_mean_enc_fold','Outlet_Identifier_mean_enc_fold','Item_MRP_clipped','Item_Identifier_freq']\n",
    "\n",
    "features.append(feature_set_0)\n",
    "features.append(feature_set_1)\n",
    "features.append(feature_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    model_pipeline = Pipeline([\n",
    "        ('reg', model_regressors[0])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET:1\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "----------------------\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "----------------------\n",
      "[0.52891079 0.51530758 0.58376602 0.54510717 0.52931285]\n",
      "0.5404808806294407\n",
      "----------------------\n",
      "FEATURE SET:1\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "----------------------\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False)\n",
      "----------------------\n",
      "[0.63274085 0.61951443 0.66290112 0.63000055 0.61635999]\n",
      "0.6323033880483899\n",
      "----------------------\n",
      "FEATURE SET:1\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "----------------------\n",
      "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "----------------------\n",
      "[0.62787089 0.62141088 0.66302613 0.63179434 0.61836331]\n",
      "0.6324931106812616\n",
      "----------------------\n",
      "FEATURE SET:1\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "----------------------\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "----------------------\n",
      "[0.59613601 0.58142528 0.62030868 0.59576165 0.58005667]\n",
      "0.594737657979312\n",
      "----------------------\n",
      "FEATURE SET:1\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "----------------------\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "----------------------\n",
      "[0.54602601 0.5399426  0.59979013 0.5566843  0.53599139]\n",
      "0.5556868876573146\n",
      "----------------------\n",
      "FEATURE SET:2\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "----------------------\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "----------------------\n",
      "[0.54839881 0.53232365 0.59190885 0.54799197 0.53037793]\n",
      "0.5502002434036903\n",
      "----------------------\n",
      "FEATURE SET:2\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "----------------------\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False)\n",
      "----------------------\n",
      "[0.62807599 0.62007516 0.66203512 0.62981403 0.61685449]\n",
      "0.6313709586627396\n",
      "----------------------\n",
      "FEATURE SET:2\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "----------------------\n",
      "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "----------------------\n",
      "[0.62737792 0.62068806 0.66334168 0.62936358 0.61853515]\n",
      "0.6318612796222569\n",
      "----------------------\n",
      "FEATURE SET:2\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "----------------------\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "----------------------\n",
      "[0.59694387 0.58180331 0.62023397 0.59522935 0.58065568]\n",
      "0.59497323534803\n",
      "----------------------\n",
      "FEATURE SET:2\n",
      "Cross-Validation Type:\n",
      "kfold\n",
      "----------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "----------------------\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "----------------------\n",
      "[0.57479914 0.54872405 0.61625681 0.5705933  0.54945125]\n",
      "0.5719649122519243\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    \n",
    "    if cv_indicator == \"kfold\":\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    elif cv_indicator == \"skfold\":\n",
    "        cv = StratifiedKFold(n_splits=3,shuffle=False,random_state=seed)\n",
    "    elif cv_indicator == 'shuffle_split':\n",
    "        cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=seed)\n",
    "    elif cv_indicator == 's_shuffle_split':\n",
    "        cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=seed)\n",
    "    elif cv_indicator == \"time\":\n",
    "        cv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    for i in range(1,(len(features))):\n",
    "        X = train_df[features[i]]\n",
    "        y = target_df[target]\n",
    "    \n",
    "        for reg in model_regressors:\n",
    "            print(\"FEATURE SET:%s\" %i)\n",
    "            print(\"Cross-Validation Type:\")\n",
    "            print(cv_indicator)\n",
    "            model_pipeline.set_params(reg=reg)\n",
    "            scores = cross_val_score(model_pipeline, X, y, scoring=scoring, cv=cv)\n",
    "            print('----------------------')\n",
    "            print(features[i])\n",
    "            print('----------------------')\n",
    "            print(str(reg))\n",
    "            print('----------------------')\n",
    "            print(scores)\n",
    "            print(scores.mean())\n",
    "            print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pipeline - Level 1: Evaluating Specific Algos & Datasets before Hyperparameter Tuning **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algos_selected_for_tuning = ['GBM','XGB']\n",
    "algo_features_dict = {\"GBM\": [1],\"XGB\":[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM ['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "XGB ['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n"
     ]
    }
   ],
   "source": [
    "for algo,feat_sets in algo_features_dict.items():\n",
    "    for i in range(0,len(feat_sets)):\n",
    "        print(algo, features[feat_sets[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "Algorithm:  GBM\n",
      "['reg', 'reg__alpha', 'reg__criterion', 'reg__init', 'reg__learning_rate', 'reg__loss', 'reg__max_depth', 'reg__max_features', 'reg__max_leaf_nodes', 'reg__min_impurity_split', 'reg__min_samples_leaf', 'reg__min_samples_split', 'reg__min_weight_fraction_leaf', 'reg__n_estimators', 'reg__presort', 'reg__random_state', 'reg__subsample', 'reg__verbose', 'reg__warm_start', 'steps']\n",
      "------------------------\n",
      "------------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "------------------------\n",
      "Pipeline(steps=[('reg', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False))])\n",
      "------------------------\n",
      "Performance before hyperparameter tuning: 1020.26\n",
      "[0.33814624 0.27984007 0.32718391 0.05482978] [0 2 1 3]\n",
      "Feature ranking:\n",
      "Index(['Item_Identifier_mean_enc_fold', 'Item_MRP_clipped',\n",
      "       'Outlet_Identifier_mean_enc_fold', 'Item_Identifier_freq'],\n",
      "      dtype='object')\n",
      "------------------------\n",
      "------------------------\n",
      "Algorithm:  XGB\n",
      "['reg', 'reg__base_score', 'reg__colsample_bylevel', 'reg__colsample_bytree', 'reg__gamma', 'reg__learning_rate', 'reg__max_delta_step', 'reg__max_depth', 'reg__min_child_weight', 'reg__missing', 'reg__n_estimators', 'reg__nthread', 'reg__objective', 'reg__reg_alpha', 'reg__reg_lambda', 'reg__scale_pos_weight', 'reg__seed', 'reg__silent', 'reg__subsample', 'steps']\n",
      "------------------------\n",
      "------------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "------------------------\n",
      "Pipeline(steps=[('reg', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1))])\n",
      "------------------------\n",
      "Performance before hyperparameter tuning: 1024.69\n",
      "Feature ranking:\n",
      "[(241, 'Item_Identifier_mean_enc_fold'), (216, 'Outlet_Identifier_mean_enc_fold'), (201, 'Item_MRP_clipped'), (29, 'Item_Identifier_freq')]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    \n",
    "    ## Creating the param grid & the model\n",
    "    pipelines_to_tune = []\n",
    "    param_grid_to_tune = []\n",
    "   \n",
    "    # 1. GBM\n",
    "    if 'GBM' in algos_selected_for_tuning:\n",
    "        gbm_pipeline = Pipeline([\n",
    "            ('reg', GradientBoostingRegressor())\n",
    "        ])\n",
    "        pipelines_to_tune.append(gbm_pipeline)\n",
    "\n",
    "    # 2. XGB\n",
    "    if 'XGB' in algos_selected_for_tuning:\n",
    "        xgb_pipeline = Pipeline([\n",
    "            ('reg', XGBRegressor())\n",
    "        ])\n",
    "        pipelines_to_tune.append(xgb_pipeline)\n",
    "        \n",
    "    # 3. RF\n",
    "    if 'RF' in algos_selected_for_tuning:\n",
    "        rf_pipeline = Pipeline([\n",
    "            ('features', tree_all_features_pipeline),\n",
    "            ('reg', RandomForestRegressor())\n",
    "        ])\n",
    "        pipelines_to_tune.append(rf_pipeline)\n",
    "    \n",
    "    # 4. Catboost\n",
    "    if 'CAT' in algos_selected_for_tuning:\n",
    "        cat_pipeline = Pipeline([\n",
    "            ('reg', CatBoostRegressor())\n",
    "        ])\n",
    "        pipelines_to_tune.append(cat_pipeline)\n",
    "        \n",
    "    # 5. Linear Regression\n",
    "    if 'LR' in algos_selected_for_tuning:\n",
    "        lr_pipeline = Pipeline([\n",
    "            ('reg', LinearRegression())\n",
    "        ])\n",
    "        pipelines_to_tune.append(lr_pipeline)     \n",
    "    \n",
    "    ## Get the parameters for models\n",
    "    for i in range(0,len(pipelines_to_tune)):\n",
    "        pipe_to_tune = pipelines_to_tune[i]\n",
    "        #param_grid = param_grid_to_tune[i]\n",
    "        print(\"------------------------\")\n",
    "        print(\"Algorithm: \",algos_selected_for_tuning[i])\n",
    "        # Get all hyper-parameters for the pipeline object\n",
    "        print(sorted(pipe_to_tune.get_params().keys()))\n",
    "        print(\"------------------------\")\n",
    "\n",
    "        feat_sets = algo_features_dict[algo]   # Get the feature sets for each algo from dict\n",
    "        \n",
    "        for j in range(0,len(feat_sets)):      # Traverse through the feature sets\n",
    "            X = train_df[features[feat_sets[j]]]\n",
    "            y = target_df[target]\n",
    "            \n",
    "            print(\"------------------------\")\n",
    "            print(features[feat_sets[j]])\n",
    "            print(\"------------------------\")\n",
    "            \n",
    "            # Creating the train-test split\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=17)\n",
    "        \n",
    "            # use the pipeline object as you would a regular regressor\n",
    "            pipe_to_tune.fit(X_train,y_train)\n",
    "            print(pipe_to_tune)\n",
    "            print(\"------------------------\")\n",
    "\n",
    "            y_preds = pipe_to_tune.predict(X_val)\n",
    "            print(\"Performance before hyperparameter tuning: %0.2f\" %rmse(y_val,y_preds))\n",
    "\n",
    "            model_for_feature_importance = pipe_to_tune.named_steps['reg']\n",
    "        \n",
    "            if (algos_selected_for_tuning[i] == \"XGB\"):\n",
    "                importances_xgb = model_for_feature_importance.booster().get_score(importance_type='weight')\n",
    "                print(\"Feature ranking:\")\n",
    "                print(sorted(((value,key) for (key,value) in importances_xgb.items()),reverse=True))\n",
    "                print(\"------------------------\")\n",
    "            else:\n",
    "                importances = _get_feature_importances(model_for_feature_importance)\n",
    "                indices = np.argsort(importances)[::-1]\n",
    "                print(importances,indices)\n",
    "\n",
    "                # Print the feature ranking\n",
    "                print(\"Feature ranking:\")\n",
    "                print(X.transpose().index[indices])\n",
    "                print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pipeline - Level 2: Hyperparameter Tuning for selected algos & datasets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm:  GBM\n",
      "[INFO] tuning hyperparameters via grid search\n",
      "pipeline: ['reg']\n",
      "parameters:\n",
      "{'reg__learning_rate': [0.01, 0.1],\n",
      " 'reg__max_depth': [2, 4],\n",
      " 'reg__n_estimators': [50]}\n",
      "------------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped_tf', 'PriceLevels_lb_enc']\n",
      "------------------------\n",
      "done in 3.893s\n",
      "\n",
      "Best score: 0.634595 using {'reg__n_estimators': 50, 'reg__learning_rate': 0.1, 'reg__max_depth': 4}\n",
      "Best parameters set:\n",
      "0.290492 (0.008921) with: {'reg__n_estimators': 50, 'reg__learning_rate': 0.01, 'reg__max_depth': 2}\n",
      "0.381806 (0.007949) with: {'reg__n_estimators': 50, 'reg__learning_rate': 0.01, 'reg__max_depth': 4}\n",
      "0.630830 (0.012885) with: {'reg__n_estimators': 50, 'reg__learning_rate': 0.1, 'reg__max_depth': 2}\n",
      "0.634594 (0.016912) with: {'reg__n_estimators': 50, 'reg__learning_rate': 0.1, 'reg__max_depth': 4}\n",
      "[INFO] search took 3.89 seconds\n",
      "----------------------------------------\n",
      "Algorithm:  XGB\n",
      "[INFO] tuning hyperparameters via grid search\n",
      "pipeline: ['reg']\n",
      "parameters:\n",
      "{'reg__learning_rate': [0.1],\n",
      " 'reg__max_depth': [2, 4],\n",
      " 'reg__n_estimators': [100]}\n",
      "------------------------\n",
      "['Item_Identifier_mean_enc_fold', 'Outlet_Identifier_mean_enc_fold', 'Item_MRP_clipped', 'Item_Identifier_freq']\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthikeyan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.132s\n",
      "\n",
      "Best score: 0.634200 using {'reg__n_estimators': 100, 'reg__learning_rate': 0.1, 'reg__max_depth': 2}\n",
      "Best parameters set:\n",
      "0.634198 (0.015490) with: {'reg__n_estimators': 100, 'reg__learning_rate': 0.1, 'reg__max_depth': 2}\n",
      "0.628068 (0.018006) with: {'reg__n_estimators': 100, 'reg__learning_rate': 0.1, 'reg__max_depth': 4}\n",
      "[INFO] search took 2.13 seconds\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthikeyan\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Creating the param grid & the model\n",
    "pipelines_to_tune = []\n",
    "param_grid_to_tune = []\n",
    "best_models = []\n",
    "best_pipelines = []\n",
    "final_feature_set = []\n",
    "algos = []\n",
    "\n",
    "if tuning_required == \"Yes\":\n",
    "   \n",
    "    # 1. GBM\n",
    "    if 'GBM' in algos_selected_for_tuning:\n",
    "        gbm_pipeline = Pipeline([\n",
    "            ('reg', GradientBoostingRegressor())\n",
    "        ])\n",
    "        \n",
    "        param_grid_gbm = { \n",
    "                 'reg__n_estimators': [50],\n",
    "                 'reg__max_depth': [2,4],\n",
    "                 'reg__learning_rate':[0.01,0.1],\n",
    "              }\n",
    "        pipelines_to_tune.append(gbm_pipeline)\n",
    "        param_grid_to_tune.append(param_grid_gbm)\n",
    "\n",
    "    # 2. XGB\n",
    "    if 'XGB' in algos_selected_for_tuning:\n",
    "        xgb_pipeline = Pipeline([\n",
    "            ('reg', XGBRegressor())\n",
    "        ])\n",
    "        param_grid_xgb = {\n",
    "             'reg__n_estimators': [100],\n",
    "             'reg__max_depth': [2,4],\n",
    "             'reg__learning_rate':[0.1],\n",
    "          }\n",
    "        pipelines_to_tune.append(xgb_pipeline)\n",
    "        param_grid_to_tune.append(param_grid_xgb)\n",
    "        \n",
    "    # 3. RF\n",
    "    if 'RF' in algos_selected_for_tuning:\n",
    "        rf_pipeline = Pipeline([\n",
    "            ('reg', RandomForestRegressor())\n",
    "        ])\n",
    "        param_grid_rf = {\n",
    "             'reg__n_estimators': [50,100,150],\n",
    "             'reg__max_depth': [2,4],\n",
    "          }\n",
    "        pipelines_to_tune.append(rf_pipeline)\n",
    "        param_grid_to_tune.append(param_grid_rf)\n",
    "    \n",
    "    ## Get the parameters for models\n",
    "    for i in range(0,len(pipelines_to_tune)):\n",
    "        pipe_to_tune = pipelines_to_tune[i]\n",
    "        param_grid = param_grid_to_tune[i]\n",
    "        algo = algos_selected_for_tuning[i]\n",
    "        print(\"Algorithm: \",algo)\n",
    "        \n",
    "        if cv_indicator == \"kfold\":\n",
    "            cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        elif cv_indicator == \"skfold\":\n",
    "            cv = StratifiedKFold(n_splits=3,shuffle=False,random_state=seed)\n",
    "        elif cv_indicator == 'shuffle_split':\n",
    "            cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=seed)\n",
    "        elif cv_indicator == 's_shuffle_split':\n",
    "            cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=seed)\n",
    "        elif cv_indicator == \"time\":\n",
    "            cv = TimeSeriesSplit(n_splits=3)\n",
    "            \n",
    "        if search == \"grid_search\":\n",
    "            ## Grid Search\n",
    "            print(\"[INFO] tuning hyperparameters via grid search\")\n",
    "            #grid = GridSearchCV(estimator=model_to_tune, param_grid=param_grid, scoring=scoring, cv=cv)\n",
    "            grid = GridSearchCV(estimator=pipe_to_tune, param_grid=param_grid,scoring=scoring,cv=cv)\n",
    "        elif search == \"random_search\":\n",
    "            ## Random Search\n",
    "            print(\"[INFO] tuning hyperparameters via random search\")\n",
    "            #grid = RandomizedSearchCV(estimator=model_to_tune, param_distributions=param_grid, scoring=scoring, cv=cv)\n",
    "            grid = RandomizedSearchCV(estimator=pipe_to_tune, param_distributions=param_grid, scoring=scoring, cv=cv)\n",
    "\n",
    "        print(\"pipeline:\", [name for name, _ in pipe_to_tune.steps])\n",
    "        print(\"parameters:\")\n",
    "        pprint(param_grid)\n",
    "        start = time.time()\n",
    "        \n",
    "        feat_sets = algo_features_dict[algo]   # Get the feature sets for each algo from dict\n",
    "        \n",
    "        for j in range(0,len(feat_sets)):      # Traverse through the feature sets\n",
    "            X = train_df[features[feat_sets[j]]]\n",
    "            y = target_df[target]\n",
    "            \n",
    "            print(\"------------------------\")\n",
    "            print(features[feat_sets[j]])\n",
    "            print(\"------------------------\")\n",
    "        \n",
    "            # Appending feature set for each algo\n",
    "            final_feature_set.append(features[feat_sets[j]])  # To be used in finalizing the pipelines\n",
    "            algos.append(algo)                                # To be used in finalizing the pipelines\n",
    "            \n",
    "            grid_result = grid.fit(X, y)  # should it be X_train, Y_train or X,y??\n",
    "            print(\"done in %0.3fs\" % (time.time() - start))\n",
    "            print()\n",
    "\n",
    "            print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "            print(\"Best parameters set:\")\n",
    "            best_parameters = grid_result.best_estimator_.get_params()\n",
    "            \n",
    "            # print(grid_result.cv_results_)  # Need to use cv_results_ as grid_scores_ is deprecated in 0.20\n",
    "            \n",
    "            for params, mean_score, scores in grid_result.grid_scores_:\n",
    "                print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))\n",
    "            print(\"[INFO] search took {:.2f} seconds\".format(time.time() - start))\n",
    "\n",
    "            #grid_result.refit\n",
    "            best_estimator = grid_result.best_estimator_\n",
    "            best_pipelines.append(best_estimator)\n",
    "            best_models.append(best_estimator.named_steps['reg'])\n",
    "            #preds = best_estimator.predict(X_val)\n",
    "            #print(\"Performance after hyperparameter tuning: %0.2f\" %rmse(y_val,preds))\n",
    "            print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Setting the final pipelines and fit to entire training set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('reg', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=4, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=50, presort='auto',\n",
      "             random_state=None, subsample=1.0, verbose=0, warm_start=False))])\n",
      "Pipeline(steps=[('reg', XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1))])\n"
     ]
    }
   ],
   "source": [
    "final_pipelines=[]\n",
    "\n",
    "for i in range(0,len(best_pipelines)):\n",
    "    pipe_for_final_prediction = best_pipelines[i]\n",
    "    feature_set_for_final_prediction = final_feature_set[i]\n",
    "    \n",
    "    X = train_df[feature_set_for_final_prediction]\n",
    "    y = target_df[target]\n",
    "    \n",
    "    print(pipe_for_final_prediction)\n",
    "    pipe_for_final_prediction.fit(X,y)\n",
    "    final_pipelines.append(pipe_for_final_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Predict on Test Set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the final predictions from each algo\n",
    "test_predictions = pd.DataFrame()\n",
    "#for i in range(0,len(algos_selected_for_tuning)):\n",
    "for i in range(0,len(final_pipelines)):\n",
    "    colname_preds = 'preds' + '_' + algos[i] + '_' + str(i)\n",
    "    feature_set_for_final_prediction = final_feature_set[i]\n",
    "    \n",
    "    #preds = np.exp(final_pipelines[i].predict(X_test))\n",
    "    X_test = test_df[feature_set_for_final_prediction]\n",
    "    \n",
    "    preds = final_pipelines[i].predict(X_test)    \n",
    "    test_predictions[colname_preds] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds_GBM_0</th>\n",
       "      <th>preds_XGB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1758.694361</td>\n",
       "      <td>1710.765381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1429.756509</td>\n",
       "      <td>1422.193237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>785.304116</td>\n",
       "      <td>754.769775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2074.811273</td>\n",
       "      <td>2106.047363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5592.207403</td>\n",
       "      <td>5704.916016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preds_GBM_0  preds_XGB_1\n",
       "0  1758.694361  1710.765381\n",
       "1  1429.756509  1422.193237\n",
       "2   785.304116   754.769775\n",
       "3  2074.811273  2106.047363\n",
       "4  5592.207403  5704.916016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(final_pipelines) > 0:\n",
    "    final_df = pd.DataFrame()\n",
    "    final_df['Item_Identifier'] = test_df['Item_Identifier']\n",
    "    final_df['Outlet_Identifier'] = test_df['Outlet_Identifier']\n",
    "    final_df['Item_Outlet_Sales'] = test_predictions['preds_GBM_0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1758.694361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524</th>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1429.756509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>785.304116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2074.811273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5592.207403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "8523           FDW58            OUT049        1758.694361\n",
       "8524           FDW14            OUT017        1429.756509\n",
       "8525           NCN55            OUT010         785.304116\n",
       "8526           FDQ58            OUT017        2074.811273\n",
       "8527           FDY38            OUT027        5592.207403"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    5681.000000\n",
      "mean     2159.018504\n",
      "std      1318.360338\n",
      "min        30.367401\n",
      "25%      1053.628876\n",
      "50%      2069.704750\n",
      "75%      3057.675615\n",
      "max      7459.409902\n",
      "Name: Item_Outlet_Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    print(final_df['Item_Outlet_Sales'].describe().T)\n",
    "    final_df.to_csv('./submit-bigmartsales-1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
